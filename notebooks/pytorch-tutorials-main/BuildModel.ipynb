{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63c324da-a5f9-4b31-95b7-e540140d60e7",
   "metadata": {},
   "source": [
    "# Build the Neural Network\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bc8d413-c197-45ab-8167-390eed054955",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6369c7e5-3090-4bf5-a842-24de2c850161",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "device = ('cuda'\n",
    "          if torch.cuda.is_available()\n",
    "          else 'mps'\n",
    "          if torch.backends.mps.is_available()\n",
    "          else 'cpu' )\n",
    "print(f'Using {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c1f6329-a503-4920-b866-7250a24add9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,10))\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "994241b6-ec70-4f8f-8edb-d6c43d5b34c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b4f0081-7f98-4929-803f-035e3948020b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: tensor([0]), probability: 0.11264409124851227\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1,28,28,device=device)\n",
    "logits = model(X)\n",
    "proba_pred = nn.Softmax(dim=1)(logits)\n",
    "y_pred = proba_pred.argmax(1)\n",
    "print(f'Predicted: {y_pred}, probability: {proba_pred[0,y_pred.item()]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44d2a177-c7c3-4803-a35c-6e7a48e47f20",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3,28,28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edfbbe80-4f0e-4843-bb13-52cf87e2c3f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16609109-1cb7-4b44-8b24-cd07a294be00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.2901, -0.0800,  0.1265, -0.1465,  0.2098, -0.9463,  0.1978,  0.4985,\n",
      "         -0.2774,  0.0060, -0.0026,  0.0096,  0.0203, -0.0253,  0.3044,  0.2478,\n",
      "          0.5302, -0.2506, -0.7631, -0.4910],\n",
      "        [ 0.2431, -0.0250,  0.2025,  0.0042,  0.1721, -1.0342, -0.1111,  0.2811,\n",
      "         -0.1498, -0.1898, -0.3414, -0.1040,  0.1245, -0.1053,  0.3549,  0.1550,\n",
      "          0.3413,  0.2220, -0.3641, -0.5157],\n",
      "        [ 0.3079, -0.0592,  0.3225, -0.0345, -0.1979, -0.8669,  0.1035, -0.1252,\n",
      "         -0.4510, -0.5338, -0.2398,  0.1201,  0.2339, -0.0157,  0.3319,  0.2493,\n",
      "          0.4681,  0.0134, -0.6208, -0.5347]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features = 28*28, out_features = 20)\n",
    "print(layer1(flat_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe5bf41b-efbc-4195-b9ad-e4fb544bad91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[ 0.2901, -0.0800,  0.1265, -0.1465,  0.2098, -0.9463,  0.1978,  0.4985,\n",
      "         -0.2774,  0.0060, -0.0026,  0.0096,  0.0203, -0.0253,  0.3044,  0.2478,\n",
      "          0.5302, -0.2506, -0.7631, -0.4910],\n",
      "        [ 0.2431, -0.0250,  0.2025,  0.0042,  0.1721, -1.0342, -0.1111,  0.2811,\n",
      "         -0.1498, -0.1898, -0.3414, -0.1040,  0.1245, -0.1053,  0.3549,  0.1550,\n",
      "          0.3413,  0.2220, -0.3641, -0.5157],\n",
      "        [ 0.3079, -0.0592,  0.3225, -0.0345, -0.1979, -0.8669,  0.1035, -0.1252,\n",
      "         -0.4510, -0.5338, -0.2398,  0.1201,  0.2339, -0.0157,  0.3319,  0.2493,\n",
      "          0.4681,  0.0134, -0.6208, -0.5347]], grad_fn=<AddmmBackward0>)\n",
      "After ReLU: tensor([[0.2901, 0.0000, 0.1265, 0.0000, 0.2098, 0.0000, 0.1978, 0.4985, 0.0000,\n",
      "         0.0060, 0.0000, 0.0096, 0.0203, 0.0000, 0.3044, 0.2478, 0.5302, 0.0000,\n",
      "         0.0000, 0.0000],\n",
      "        [0.2431, 0.0000, 0.2025, 0.0042, 0.1721, 0.0000, 0.0000, 0.2811, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.1245, 0.0000, 0.3549, 0.1550, 0.3413, 0.2220,\n",
      "         0.0000, 0.0000],\n",
      "        [0.3079, 0.0000, 0.3225, 0.0000, 0.0000, 0.0000, 0.1035, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.1201, 0.2339, 0.0000, 0.3319, 0.2493, 0.4681, 0.0134,\n",
      "         0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "hidden1 = layer1(flat_image)\n",
    "print(f'Before ReLU: {hidden1}')\n",
    "relu1 = nn.ReLU()(hidden1)\n",
    "print(f'After ReLU: {relu1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d05a644e-1887-444b-8218-a4733c0ba91b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "906042ff-b425-4997-b708-46aef1a65749",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values: Parameter containing:\n",
      "tensor([[ 0.0030, -0.0128,  0.0171,  ..., -0.0244, -0.0250,  0.0111],\n",
      "        [ 0.0168, -0.0273,  0.0021,  ..., -0.0242, -0.0008, -0.0232],\n",
      "        [-0.0289, -0.0264,  0.0070,  ...,  0.0243, -0.0162,  0.0340],\n",
      "        ...,\n",
      "        [ 0.0071, -0.0162,  0.0051,  ...,  0.0230,  0.0290, -0.0158],\n",
      "        [-0.0230, -0.0045,  0.0023,  ..., -0.0020,  0.0207,  0.0271],\n",
      "        [-0.0125,  0.0240,  0.0029,  ...,  0.0022,  0.0004, -0.0006]],\n",
      "       requires_grad=True) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values: Parameter containing:\n",
      "tensor([ 2.4006e-02, -6.7358e-03, -4.0426e-03,  3.0495e-02, -3.3796e-02,\n",
      "        -2.8599e-02, -2.5223e-02,  2.2750e-02,  3.1241e-02, -3.5317e-03,\n",
      "         1.2756e-02, -2.9143e-02, -2.9807e-02, -8.2488e-04,  2.7288e-02,\n",
      "         6.2555e-05,  3.4708e-02,  3.4400e-04,  9.7375e-03,  2.7271e-02,\n",
      "         2.8348e-02, -3.5094e-02,  1.3489e-02, -2.8377e-02,  6.3440e-03,\n",
      "        -1.1091e-02, -2.0503e-02, -1.6688e-02,  2.8191e-02, -2.9985e-02,\n",
      "        -2.3397e-02, -1.7694e-02,  2.7760e-02,  2.2777e-02,  3.5451e-02,\n",
      "         1.3336e-02, -3.4151e-02,  2.7866e-02, -2.8976e-03, -3.5034e-02,\n",
      "        -3.8158e-03, -1.5595e-02,  3.3984e-04, -6.5734e-03, -7.8200e-03,\n",
      "        -3.1503e-02, -9.4376e-03, -1.2028e-02, -7.4881e-03,  7.4907e-03,\n",
      "         1.9871e-02,  2.8849e-02,  3.0179e-02,  2.2543e-02, -5.3530e-03,\n",
      "        -1.9474e-02, -1.8343e-02, -1.3999e-02, -6.8197e-03, -1.0546e-02,\n",
      "        -2.0148e-02,  3.0788e-02,  3.3342e-02,  8.7019e-03, -2.7106e-02,\n",
      "        -2.8356e-02,  4.6623e-03,  1.9992e-02,  1.6683e-02,  2.3995e-02,\n",
      "        -3.0138e-03,  2.4538e-02, -3.0889e-02,  2.2182e-02, -6.0415e-04,\n",
      "        -6.7955e-03, -3.3973e-02, -3.0112e-02, -2.7891e-02,  7.3363e-03,\n",
      "        -3.0339e-02,  2.5679e-02,  6.2073e-04,  1.7638e-02, -2.0085e-02,\n",
      "         2.0612e-02,  1.5707e-04, -2.9074e-03,  1.9046e-02, -1.6529e-02,\n",
      "         2.8077e-02, -6.8447e-04, -3.0263e-02, -8.1161e-04, -3.0631e-02,\n",
      "         1.5841e-02, -2.3706e-02, -1.3176e-02, -9.2739e-03,  1.2086e-02,\n",
      "        -2.2712e-02,  1.6769e-02, -3.2926e-02,  3.2396e-02,  9.5449e-03,\n",
      "         1.3157e-02, -3.5152e-02,  2.7686e-02, -3.2139e-03,  1.8229e-02,\n",
      "        -2.6919e-02, -3.2412e-02, -2.7949e-02,  1.2607e-02, -2.0184e-02,\n",
      "         2.5252e-02, -1.6292e-02,  4.6367e-03,  1.9728e-02, -2.9473e-02,\n",
      "        -1.1161e-02, -1.0847e-03,  3.5014e-02,  1.6220e-02, -6.4932e-03,\n",
      "         1.4650e-02, -1.4586e-02, -5.7323e-03,  1.4216e-02, -2.8015e-02,\n",
      "         2.1920e-02,  1.0601e-02,  8.6132e-03, -1.4379e-02, -2.4618e-02,\n",
      "        -2.0712e-02, -5.2045e-03, -1.3931e-02,  3.1392e-02,  2.0027e-02,\n",
      "        -2.9331e-02,  2.1493e-02, -1.4817e-02, -1.6950e-02,  1.4362e-02,\n",
      "        -2.7857e-02,  3.2977e-03,  9.7330e-03,  1.1176e-02,  1.1926e-02,\n",
      "        -1.2886e-02,  2.3141e-02,  2.9868e-02,  2.2040e-02, -2.5265e-02,\n",
      "        -1.0994e-02,  1.6360e-02, -8.1300e-04, -6.4962e-03,  2.6702e-02,\n",
      "        -2.3571e-02,  3.0046e-02, -1.6597e-02, -2.3373e-02, -2.0319e-02,\n",
      "         1.6826e-02,  2.7806e-02,  1.7370e-04, -4.2916e-03,  7.5968e-03,\n",
      "         3.2170e-02,  2.7925e-03, -9.5473e-03,  2.5439e-04,  2.7456e-03,\n",
      "        -3.2287e-02, -9.3699e-03,  1.3492e-02, -2.0572e-02,  4.9325e-03,\n",
      "        -1.2424e-02, -2.2694e-02,  3.0026e-02,  2.4051e-02,  2.7477e-02,\n",
      "         2.4769e-02,  9.7447e-03,  3.4851e-02,  1.4536e-03, -1.9027e-02,\n",
      "         2.6954e-02,  2.3748e-02,  2.4196e-02,  1.3889e-03, -1.1841e-02,\n",
      "        -1.0799e-02,  1.1792e-02, -2.4349e-02, -9.3317e-03, -1.9827e-03,\n",
      "         1.8753e-02,  1.7583e-02, -2.5280e-02,  1.7151e-02,  2.5814e-02,\n",
      "        -2.7523e-02,  7.6303e-03,  1.4173e-02, -1.6988e-02, -5.6686e-03,\n",
      "         2.1632e-02, -2.6406e-02, -2.1887e-02,  2.5227e-02,  1.2442e-02,\n",
      "        -1.4930e-02, -1.3821e-02,  2.5337e-02, -1.3953e-02,  3.8284e-03,\n",
      "         1.9014e-02, -2.7784e-02,  1.2883e-02,  3.1047e-02, -1.0010e-02,\n",
      "         1.3089e-02, -5.4747e-03, -7.5057e-03, -3.1676e-02,  1.6849e-03,\n",
      "         9.8230e-03, -3.3488e-02,  2.1909e-02, -3.1125e-02,  2.7478e-02,\n",
      "        -6.2205e-03,  3.2545e-03,  2.0730e-02,  7.8178e-03, -1.4941e-02,\n",
      "         4.0972e-03,  3.2124e-02, -8.4324e-03,  3.0196e-02, -3.0215e-02,\n",
      "        -9.9503e-03, -2.2577e-02,  1.3321e-02, -1.4017e-02, -2.2403e-02,\n",
      "         2.6706e-02,  1.5990e-02, -1.6641e-02, -2.6597e-02,  2.7751e-02,\n",
      "         1.5680e-02,  1.6810e-02, -2.2884e-02, -1.5679e-02, -2.5976e-02,\n",
      "         2.8783e-02, -3.8346e-03,  3.3297e-04, -3.2636e-02, -2.0346e-02,\n",
      "        -2.6044e-02,  2.1849e-03, -2.0511e-02,  3.1747e-02,  7.8622e-04,\n",
      "         2.3144e-02, -3.1400e-02, -2.8678e-02, -7.5152e-03,  2.8333e-03,\n",
      "        -9.9864e-03,  2.6842e-02, -2.7917e-02, -2.5310e-02, -2.3243e-02,\n",
      "        -1.8524e-03, -6.7371e-03,  2.7962e-02,  2.5951e-02,  1.0618e-02,\n",
      "         3.3268e-02,  1.5832e-02,  5.9021e-03, -6.8208e-03,  2.7578e-02,\n",
      "        -1.8487e-02,  8.7202e-03, -5.9957e-03,  3.2436e-02,  3.3902e-02,\n",
      "        -2.1719e-03,  1.5575e-02, -1.2067e-02, -1.9239e-02, -3.4670e-02,\n",
      "         2.5646e-02,  3.2896e-02, -3.4854e-02, -2.4028e-05, -7.8536e-03,\n",
      "        -2.8005e-02, -3.4985e-02,  1.5913e-02, -2.4141e-02, -2.0308e-02,\n",
      "         3.1842e-02, -2.9837e-02, -3.4861e-02, -1.9356e-02, -2.3042e-02,\n",
      "         2.1747e-02, -3.4069e-02,  5.6439e-03,  1.3851e-02,  5.8237e-03,\n",
      "         3.2401e-02,  1.3674e-02,  2.9073e-02, -3.4410e-02,  2.9166e-02,\n",
      "         1.5676e-02, -1.0430e-02,  1.5989e-02, -3.3549e-02,  2.9759e-02,\n",
      "        -3.0995e-02,  2.0416e-02, -2.6417e-02, -2.7680e-02,  2.2548e-02,\n",
      "        -2.6615e-03, -1.2371e-02, -2.3881e-02, -2.0371e-03,  1.8793e-02,\n",
      "        -2.9925e-03, -3.1175e-02, -1.7567e-02, -1.7434e-02,  2.9688e-03,\n",
      "        -1.9586e-02,  1.1473e-02,  2.2872e-02, -1.0848e-02,  2.9368e-02,\n",
      "        -1.1627e-02, -2.7303e-02, -5.7720e-04, -1.1924e-04, -3.2832e-03,\n",
      "        -1.5079e-02,  9.5017e-03, -2.6461e-02, -8.3756e-03,  7.1497e-03,\n",
      "         2.8714e-03,  8.1397e-04, -8.8229e-04,  2.7752e-03, -1.3442e-02,\n",
      "        -6.8790e-03, -2.9334e-02, -2.5447e-02,  4.5026e-04, -2.7996e-02,\n",
      "         2.8608e-02, -1.1881e-02, -4.0867e-03,  2.8316e-02,  3.0532e-02,\n",
      "        -2.1265e-02, -2.8461e-03,  1.1711e-02,  1.1875e-02,  2.5270e-02,\n",
      "         3.3401e-03, -1.4928e-02,  2.0584e-02, -1.2479e-02,  8.3133e-03,\n",
      "        -1.9677e-02,  3.1480e-03, -1.4721e-02, -1.7149e-03,  1.2460e-02,\n",
      "         3.2257e-02,  4.5185e-03,  2.3768e-02, -3.0185e-02,  3.2666e-02,\n",
      "        -8.2293e-03,  3.5029e-02, -2.4704e-02, -1.3930e-03, -8.7544e-03,\n",
      "         3.3045e-02, -2.4855e-02, -3.1460e-02, -1.3202e-02, -3.5485e-02,\n",
      "        -1.2743e-02,  1.8166e-02, -1.3325e-02, -3.2835e-02, -1.9171e-02,\n",
      "         1.0051e-02,  3.2595e-02, -3.1357e-02, -9.3118e-03,  8.8636e-04,\n",
      "        -3.2219e-02, -3.7442e-03, -1.8058e-03,  1.3123e-02, -7.6241e-03,\n",
      "         2.6651e-02, -6.8977e-04, -2.9832e-02,  1.1923e-02,  1.8745e-02,\n",
      "        -2.8733e-03,  5.3352e-04, -1.6454e-02, -8.4263e-03,  7.2051e-03,\n",
      "         3.1063e-02,  2.5041e-02,  2.2679e-02, -2.6734e-02,  1.8366e-02,\n",
      "        -4.9795e-03, -2.1435e-02,  1.1693e-03, -4.7424e-03,  2.8004e-03,\n",
      "        -1.3609e-02, -1.4936e-02, -3.3569e-02,  2.9362e-02,  2.5633e-02,\n",
      "         1.0014e-02, -7.9478e-03, -3.2856e-03,  2.0944e-02, -2.4827e-02,\n",
      "         8.9286e-03, -3.4976e-02, -1.3060e-02, -2.1528e-02,  7.6526e-03,\n",
      "        -1.7493e-02, -5.7972e-03, -2.5341e-02,  3.2992e-02, -2.9580e-02,\n",
      "        -2.3168e-02,  3.8019e-03,  3.2277e-02,  1.0143e-02, -2.2016e-02,\n",
      "        -6.4352e-03, -6.2521e-03,  3.1309e-02,  1.4713e-02, -2.0715e-03,\n",
      "         1.0915e-03,  1.6910e-02,  3.2077e-03,  2.0951e-02,  2.4061e-02,\n",
      "         3.2747e-02, -2.6218e-02, -2.4329e-03, -1.8543e-02, -3.1334e-02,\n",
      "         2.2745e-02, -3.2445e-02, -1.5794e-02,  3.2329e-02, -7.2600e-03,\n",
      "        -3.4086e-02, -1.5323e-03, -9.1314e-03,  1.6434e-02, -3.3074e-02,\n",
      "         7.5214e-03, -1.5992e-02,  3.5283e-02,  3.0759e-03, -1.4205e-02,\n",
      "         3.1742e-02, -1.4867e-02,  2.9003e-03,  1.4164e-02,  2.8391e-02,\n",
      "         1.1713e-03,  1.9664e-02,  1.3138e-02,  2.2796e-03,  1.7289e-02,\n",
      "         2.5075e-02, -7.3537e-03, -2.2339e-02,  1.6247e-02, -1.3370e-03,\n",
      "        -1.3434e-02,  4.6356e-03], requires_grad=True) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values: Parameter containing:\n",
      "tensor([[ 0.0291, -0.0046,  0.0248,  ...,  0.0079, -0.0101, -0.0156],\n",
      "        [ 0.0081, -0.0134,  0.0389,  ...,  0.0300, -0.0196,  0.0096],\n",
      "        [-0.0061,  0.0317,  0.0223,  ...,  0.0102, -0.0220,  0.0430],\n",
      "        ...,\n",
      "        [ 0.0053, -0.0211, -0.0145,  ...,  0.0164,  0.0434, -0.0116],\n",
      "        [ 0.0043, -0.0097, -0.0065,  ...,  0.0120,  0.0334,  0.0298],\n",
      "        [-0.0331, -0.0136, -0.0066,  ...,  0.0229, -0.0305, -0.0165]],\n",
      "       requires_grad=True) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values: Parameter containing:\n",
      "tensor([ 0.0096,  0.0274,  0.0167, -0.0389,  0.0275,  0.0156,  0.0402,  0.0370,\n",
      "         0.0331,  0.0352,  0.0268,  0.0189, -0.0158,  0.0017, -0.0135, -0.0013,\n",
      "        -0.0282, -0.0354,  0.0098, -0.0409, -0.0316, -0.0270, -0.0159,  0.0038,\n",
      "         0.0152,  0.0279,  0.0349, -0.0194, -0.0394,  0.0368,  0.0234, -0.0364,\n",
      "        -0.0289,  0.0130, -0.0170, -0.0004,  0.0351,  0.0251,  0.0371,  0.0104,\n",
      "        -0.0161, -0.0347, -0.0258,  0.0410, -0.0188,  0.0216, -0.0282,  0.0009,\n",
      "         0.0223, -0.0416, -0.0265, -0.0344, -0.0249,  0.0177, -0.0129, -0.0003,\n",
      "         0.0441,  0.0005,  0.0048,  0.0079, -0.0073, -0.0113,  0.0285,  0.0315,\n",
      "         0.0015,  0.0077, -0.0238, -0.0073, -0.0175, -0.0067, -0.0322,  0.0039,\n",
      "        -0.0167, -0.0020,  0.0132, -0.0348,  0.0139, -0.0097,  0.0422, -0.0295,\n",
      "        -0.0421,  0.0301,  0.0088, -0.0309,  0.0032,  0.0081,  0.0127, -0.0071,\n",
      "         0.0005,  0.0040,  0.0120,  0.0065,  0.0100,  0.0286,  0.0115, -0.0320,\n",
      "         0.0040,  0.0168, -0.0337,  0.0165, -0.0174,  0.0012,  0.0225, -0.0390,\n",
      "         0.0075,  0.0241,  0.0435,  0.0075, -0.0214, -0.0001,  0.0289, -0.0006,\n",
      "         0.0004, -0.0030, -0.0415, -0.0073, -0.0080,  0.0357,  0.0428,  0.0400,\n",
      "        -0.0092,  0.0023, -0.0042,  0.0239, -0.0237, -0.0184,  0.0052,  0.0134,\n",
      "        -0.0100,  0.0267,  0.0289,  0.0123,  0.0372,  0.0396, -0.0331,  0.0375,\n",
      "        -0.0400, -0.0024, -0.0355,  0.0349,  0.0029,  0.0234, -0.0210, -0.0139,\n",
      "         0.0210, -0.0386, -0.0284,  0.0246, -0.0218, -0.0172,  0.0071, -0.0310,\n",
      "         0.0320,  0.0434, -0.0010, -0.0089,  0.0400,  0.0054,  0.0350,  0.0266,\n",
      "         0.0360, -0.0248,  0.0180,  0.0308,  0.0423,  0.0012, -0.0267,  0.0262,\n",
      "         0.0365,  0.0346,  0.0053, -0.0412, -0.0329,  0.0215,  0.0037,  0.0024,\n",
      "         0.0412,  0.0082, -0.0175,  0.0367,  0.0001, -0.0390,  0.0401,  0.0013,\n",
      "         0.0125,  0.0112,  0.0159,  0.0361,  0.0389, -0.0335, -0.0336,  0.0162,\n",
      "        -0.0063, -0.0015,  0.0323, -0.0119,  0.0179, -0.0301, -0.0228, -0.0167,\n",
      "         0.0107,  0.0074,  0.0280,  0.0281, -0.0273,  0.0389, -0.0113,  0.0402,\n",
      "        -0.0239, -0.0259,  0.0416,  0.0073,  0.0116, -0.0047, -0.0058, -0.0188,\n",
      "         0.0430,  0.0143, -0.0209,  0.0239, -0.0185, -0.0062,  0.0215,  0.0200,\n",
      "         0.0275, -0.0018,  0.0354, -0.0136, -0.0180, -0.0305,  0.0309, -0.0379,\n",
      "        -0.0154, -0.0427,  0.0072,  0.0090, -0.0246,  0.0423, -0.0195, -0.0340,\n",
      "         0.0344,  0.0247,  0.0253, -0.0154, -0.0335, -0.0405,  0.0309, -0.0171,\n",
      "         0.0181, -0.0050, -0.0405,  0.0226, -0.0050, -0.0133,  0.0079, -0.0184,\n",
      "         0.0172, -0.0301, -0.0345,  0.0182,  0.0372,  0.0375,  0.0045, -0.0207,\n",
      "         0.0273,  0.0078, -0.0025, -0.0158, -0.0043, -0.0408,  0.0026, -0.0417,\n",
      "         0.0181,  0.0061, -0.0261,  0.0427, -0.0135, -0.0077, -0.0168,  0.0312,\n",
      "        -0.0091, -0.0343,  0.0167,  0.0159, -0.0072, -0.0399,  0.0068,  0.0081,\n",
      "         0.0437,  0.0324, -0.0391, -0.0239,  0.0357,  0.0428,  0.0440, -0.0076,\n",
      "         0.0074,  0.0240,  0.0214, -0.0248,  0.0137, -0.0167,  0.0262,  0.0337,\n",
      "         0.0205,  0.0200, -0.0093,  0.0320, -0.0017, -0.0397,  0.0431, -0.0145,\n",
      "         0.0220,  0.0296,  0.0250, -0.0085, -0.0338,  0.0139, -0.0341, -0.0013,\n",
      "         0.0198,  0.0412,  0.0316, -0.0050, -0.0058, -0.0012, -0.0433, -0.0373,\n",
      "         0.0396, -0.0222, -0.0393,  0.0222, -0.0416, -0.0092,  0.0084, -0.0026,\n",
      "         0.0171, -0.0049, -0.0029,  0.0035, -0.0072,  0.0031,  0.0429, -0.0168,\n",
      "        -0.0221, -0.0219,  0.0407, -0.0076,  0.0343, -0.0112, -0.0415,  0.0339,\n",
      "        -0.0290,  0.0177, -0.0366,  0.0244, -0.0104,  0.0140,  0.0316, -0.0130,\n",
      "        -0.0088, -0.0223, -0.0028, -0.0276, -0.0037, -0.0013,  0.0257, -0.0325,\n",
      "         0.0334, -0.0069, -0.0120,  0.0211, -0.0202, -0.0254,  0.0340,  0.0234,\n",
      "         0.0398,  0.0120,  0.0085, -0.0353,  0.0419, -0.0003,  0.0086,  0.0065,\n",
      "        -0.0317, -0.0049, -0.0127,  0.0163, -0.0266, -0.0293,  0.0243,  0.0285,\n",
      "        -0.0044, -0.0373,  0.0204, -0.0133, -0.0067,  0.0179, -0.0403,  0.0084,\n",
      "         0.0079,  0.0157,  0.0042, -0.0096, -0.0067, -0.0121, -0.0283,  0.0079,\n",
      "        -0.0026, -0.0346,  0.0177,  0.0440, -0.0072,  0.0350,  0.0324, -0.0127,\n",
      "        -0.0360,  0.0276,  0.0401, -0.0302, -0.0033, -0.0180,  0.0381,  0.0263,\n",
      "         0.0099,  0.0131,  0.0374,  0.0429, -0.0421,  0.0361, -0.0245, -0.0394,\n",
      "        -0.0409, -0.0342,  0.0133,  0.0229, -0.0101,  0.0041, -0.0385, -0.0325,\n",
      "        -0.0062,  0.0165, -0.0111, -0.0298, -0.0343, -0.0157, -0.0176,  0.0081,\n",
      "         0.0306, -0.0180,  0.0025,  0.0244, -0.0174, -0.0191, -0.0082, -0.0143,\n",
      "        -0.0127,  0.0088, -0.0293, -0.0333,  0.0422, -0.0028,  0.0353,  0.0178,\n",
      "        -0.0288,  0.0349, -0.0282,  0.0437,  0.0433, -0.0441,  0.0061,  0.0064,\n",
      "        -0.0256,  0.0183,  0.0430,  0.0242, -0.0076,  0.0007, -0.0116, -0.0230,\n",
      "         0.0255,  0.0374,  0.0322,  0.0137,  0.0310,  0.0303, -0.0397,  0.0202,\n",
      "        -0.0399, -0.0045, -0.0342,  0.0037,  0.0167, -0.0235, -0.0152, -0.0191,\n",
      "        -0.0354,  0.0252, -0.0209, -0.0056,  0.0418,  0.0106,  0.0364, -0.0296,\n",
      "         0.0107,  0.0294, -0.0302, -0.0131,  0.0276,  0.0330,  0.0074, -0.0118],\n",
      "       requires_grad=True) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values: Parameter containing:\n",
      "tensor([[ 0.0400, -0.0060,  0.0250,  ...,  0.0220, -0.0195,  0.0215],\n",
      "        [-0.0041, -0.0421, -0.0098,  ..., -0.0223,  0.0403, -0.0265],\n",
      "        [ 0.0424, -0.0368, -0.0208,  ...,  0.0299,  0.0380, -0.0381],\n",
      "        ...,\n",
      "        [-0.0099,  0.0044,  0.0390,  ...,  0.0018, -0.0211, -0.0391],\n",
      "        [ 0.0426, -0.0259,  0.0127,  ...,  0.0284,  0.0272, -0.0283],\n",
      "        [ 0.0399, -0.0343, -0.0268,  ..., -0.0166,  0.0428,  0.0189]],\n",
      "       requires_grad=True) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values: Parameter containing:\n",
      "tensor([-0.0140,  0.0173, -0.0024,  0.0126, -0.0348,  0.0348, -0.0190,  0.0384,\n",
      "         0.0218, -0.0176], requires_grad=True) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f'Layer: {name} | Size: {param.size()} | Values: {param} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd51b27f-1ad3-4587-9b24-806af8c4266f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
